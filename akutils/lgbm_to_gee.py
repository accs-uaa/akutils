# -*- coding: utf-8 -*-
# ---------------------------------------------------------------------------
# LightGBM to GEE
# Author: Timm Nawrocki, Matt Macander
# Last Updated: 2025-10-02
# Usage: Must be executed in an Anaconda Python 3.12+ distribution.
# Description: "LightGBM to GEE" is a set of functions to convert LightGBM model boosters to GEE-compatible tree strings.
# ---------------------------------------------------------------------------

# Import packages
import numpy as np
import pandas as pd

def treedf_to_string(df):
    """
    Description: converts a parsed LightGBM tree dataframe to a GEE-compatible string.
    Inputs: 'df' -- a dataframe representing a single tree from a LightGBM model
    Returned Value: returns a string representation of the tree
    Preconditions: requires a dataframe generated by lgbm_booster_to_tree_df
    """
    # https://github.com/giswqs/geemap/blob/master/geemap/ml.py
    # the table representation does not have lef vs right node structure
    # so we need to add in right nodes in the correct location
    # we do this by first calculating which nodes are right and then insert them at the correct index

    # get a dict of right node rows and assign key based on index where to insert
    inserts = {}
    for row in df.itertuples():
        child_r = row.children_right
        if child_r > row.Index:
            ordered_row = np.array(row)
            ordered_row[-1] = ">"
            inserts[child_r] = ordered_row[1:]  # drop index value
    # sort the inserts as to keep track of the additive indexing
    inserts_sorted = {k: inserts[k] for k in sorted(inserts.keys())}

    # loop through the row inserts and add to table (array)
    table_values = df.values
    for i, k in enumerate(inserts_sorted.keys()):
        table_values = np.insert(table_values, (k + i), inserts_sorted[k], axis=0)

    # make the ordered table array into a dataframe
    # note: df is dtype "object", need to cast later on
    ordered_df = pd.DataFrame(table_values, columns=df.columns)

    max_depth = np.max(ordered_df.node_depth.astype(int))
    tree_str = f"1) root {df['n_samples'][0]} 9999 9999 ({df['criterion'].sum()})\n"
    previous_depth = -1
    cnts = []
    # loop through the nodes and calculate the node number and values per node
    for row in ordered_df.itertuples():
        node_depth = int(row.node_depth)
        left = int(row.children_left)
        right = int(row.children_right)
        if left != right:
            if row.Index == 0:
                cnt = 2
            elif previous_depth > node_depth:
                depths = ordered_df.node_depth.values[: row.Index]
                idx = np.where(depths == node_depth)[0][-1]
                # cnt = (cnts[row.Index-1] // 2) + 1
                cnt = cnts[idx] + 1
            elif previous_depth < node_depth:
                cnt = cnts[row.Index - 1] * 2
            elif previous_depth == node_depth:
                cnt = cnts[row.Index - 1] + 1

            if node_depth == (max_depth - 1):
                value = float(ordered_df.iloc[row.Index + 1].value)
                samps = int(ordered_df.iloc[row.Index + 1].n_samples)
                criterion = float(ordered_df.iloc[row.Index + 1].criterion)
                tail = " *\n"
            else:
                if (
                        (bool(ordered_df.loc[ordered_df.node_id == left].iloc[0].is_leaf))
                        and (
                        bool(
                            int(row.Index)
                            < int(ordered_df.loc[ordered_df.node_id == left].index[0])
                        )
                )
                        and (str(row.sign) == "<=")
                ):
                    rowx = ordered_df.loc[ordered_df.node_id == left].iloc[0]
                    tail = " *\n"
                    value = float(rowx.value)
                    samps = int(rowx.n_samples)
                    criterion = float(rowx.criterion)

                elif (
                        (bool(ordered_df.loc[ordered_df.node_id == right].iloc[0].is_leaf))
                        and (
                        bool(
                            int(row.Index)
                            < int(ordered_df.loc[ordered_df.node_id == right].index[0])
                        )
                )
                        and (str(row.sign) == ">")
                ):
                    rowx = ordered_df.loc[ordered_df.node_id == right].iloc[0]
                    tail = " *\n"
                    value = float(rowx.value)
                    samps = int(rowx.n_samples)
                    criterion = float(rowx.criterion)

                else:
                    value = float(row.value)
                    samps = int(row.n_samples)
                    criterion = float(row.criterion)
                    tail = "\n"

            # extract out the information needed in each line
            spacing = (node_depth + 1) * "  "  # for pretty printing
            fname = str(row.feature_name)  # name of the feature (i.e. band name)
            tresh = float(row.threshold)  # threshold
            sign = str(row.sign)

            tree_str += f"{spacing}{cnt}) {fname} {sign} {tresh:.6f} {samps} {criterion:.4f} {value:.6f}{tail}"
            previous_depth = node_depth
        cnts.append(cnt)

    return tree_str

def lgbm_booster_to_tree_df(booster):
    """
    Description: converts a LightGBM booster object to a parsed dataframe.
    Inputs: 'booster' -- a LightGBM booster object
    Returned Value: returns a dataframe of all trees in the booster
    Preconditions: requires a trained LightGBM model
    """
    # Convert classifier or regressor (saved using .booster_.save_model) to parsed data frame
    classifier_df = booster.trees_to_dataframe()

    classifier_df["row_id"] = classifier_df.index

    classifier_df["node_id"] = classifier_df.groupby("tree_index")["row_id"].rank(method="first", ascending=True)
    classifier_df["node_id"] = classifier_df["node_id"] - 1
    classifier_df["node_id"] = classifier_df["node_id"].astype('Int64')

    classifier_nodes = classifier_df[['tree_index','node_index','node_id']]

    classifier_df = classifier_df.rename(columns={
                                         "split_gain":"criterion",
                                         "count":"n_samples",
                                         "split_feature":"feature_name"})

    classifier_df["is_leaf"] = pd.isnull(classifier_df["threshold"])
    classifier_df["sign"] = "<="
    classifier_df["node_depth"] = classifier_df["node_depth"] - 1

    classifier_df = pd.merge(classifier_df, classifier_nodes, how='left', left_on=['tree_index','left_child'], right_on=['tree_index','node_index'])
    classifier_df = classifier_df.rename(columns={"node_id_x":"node_id",
                                                   "node_id_y":"children_left"})
    # classifier_df = classifier_df.fillna(-1)
    classifier_df = pd.merge(classifier_df, classifier_nodes, how='left', left_on=['tree_index','right_child'], right_on=['tree_index','node_index'])
    classifier_df = classifier_df.rename(columns={"node_id_x":"node_id",
                                                   "node_id_y":"children_right"})

    classifier_df_out = classifier_df
    classifier_df_out = classifier_df[["tree_index",
                                       "node_id","node_depth","is_leaf","children_left","children_right","value","criterion",
                                      "n_samples","threshold","feature_name","sign"]]
    # classifier_df_out.dtypes
    # classifier_nodes
    classifier_df_out = classifier_df_out.fillna(value={'threshold': -2, 'children_right': -1, 'children_left': -1, 'criterion': 0})

    return classifier_df_out
